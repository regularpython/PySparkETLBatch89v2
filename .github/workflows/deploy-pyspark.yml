name: Deploy PySpark Script to S3

on:
  push:
    branches:
      - master   # Trigger only when code is merged into main branch

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout repository
      - name: Checkout Code
        uses: actions/checkout@v4

      # Step 2: Configure AWS credentials (requires secrets in GitHub)
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:  ${{ secrets.AWS_REGION }}

      # Step 3: Upload the PySpark script to S3
      - name: Upload Script to S3
        run: |
          aws s3 cp PySparkETLBatch89v2/jobs/pyspark_test.py \
          s3://batch89-pyspark/PySparkScripts/pyspark_test.py --exact-timestamps
